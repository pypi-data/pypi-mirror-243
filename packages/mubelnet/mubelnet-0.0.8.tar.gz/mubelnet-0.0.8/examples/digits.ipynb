{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "1c8623ce",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "2023-11-24 13:27:54.692910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
               ]
            }
         ],
         "source": [
            "from functools import partial\n",
            "\n",
            "from matplotlib import pyplot as plt\n",
            "import numpy as np\n",
            "from sklearn import datasets\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "# Run the following before any XLA modules such as JAX:\n",
            "import chex\n",
            "\n",
            "chex.set_n_cpu_devices(2)\n",
            "\n",
            "# Import the remaining JAX related\n",
            "from mubelnet.mcmc import sample_markov_chain\n",
            "from mubelnet.nets import MultinomialBelief\n",
            "from mubelnet.utils import freeze_trainable_states, holdout_split, perplexity\n",
            "\n",
            "import haiku as hk\n",
            "import jax\n",
            "from jax import random\n",
            "import jax.numpy as jnp"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "id": "0234db6d",
         "metadata": {},
         "source": [
            "To illustrate how to use the multinomial belief network, we will train the\n",
            "model on the UCI ML datasets, containing handwritten digits.\n",
            "\n",
            "The dataset can directly be loaded from scikit-learn. As preprocessing step, we reshape the\n",
            "digits from a 8x8 square matrix to a flat array of size 64."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "b51a7b7b",
         "metadata": {},
         "outputs": [],
         "source": [
            "digits = datasets.load_digits()\n",
            "n_samples = len(digits.images)\n",
            "X = digits.images.reshape((n_samples, -1))\n",
            "X_train, X_test = train_test_split(X, test_size=0.2, random_state=0)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "id": "b2a8f4f6",
         "metadata": {},
         "source": [
            "Next, we define the model. We use a simple decoder network with two hidden layers. In\n",
            "total, the size of the network: 2 x 10 x 64.\n",
            "\n",
            "```\n",
            "hidden_units = (2, 10)\n",
            "model = MultinomialBelief(hidden_units, n_features)\n",
            "```\n",
            "\n",
            "This function has to be defined in a [haiku](https://github.com/deepmind/dm-haiku) context to transform the network in a pure state for JAX.\n",
            "\n",
            "Since the network is a Bayesian model, we don't train the model by\n",
            "minimising a loss. Rather, we infer the distribution $p(\\boldsymbol{\\theta}|\\boldsymbol{X}_{\\mathrm{train}})$ of the model's parameters $\\boldsymbol{\\theta}$ given the training data $\\boldsymbol{X}_{\\mathrm{train}}$ that we observe. This probability distribution is called the [posterior](https://en.wikipedia.org/wiki/Posterior_probability).\n",
            "\n",
            "Unfortunately, we don't know what this distribution is. However, we do know a way how to sample it: using Markov chain Monte Carlo (MCMC). This simulation method samples the distributions by taking small steps that depend on its previous state. In theory, when we have take enough steps, the state converges to the true (posterior) distribution.\n",
            "\n",
            "To take one step, you simply call your model using\n",
            "the training data:\n",
            "\n",
            "```python\n",
            "model(X_train)\n",
            "```\n",
            "\n",
            "This function call does one Gibbs sampling step, which updates all the parameters one-by-one. The initialisation of the chain  (which are initialised with ancesetral samples) is automatically taken care for you.\n",
            "\n",
            "Now, lets put all elements together."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "5ab28182",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Pseudo-random number generator sequence.\n",
            "key_seq = hk.PRNGSequence(42)\n",
            "\n",
            "m_samples, n_features = X_train.shape\n",
            "\n",
            "@hk.transform_with_state\n",
            "def kernel(X=X_train, training=True):\n",
            "    \"\"\"Advance the Markov chain by one step.\"\"\"\n",
            "    hidden_units = (2, 10)\n",
            "    model = MultinomialBelief(hidden_units, n_features)\n",
            "    # Do one Gibbs sampling step.\n",
            "    model(X)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "id": "0d4cbcc7",
         "metadata": {},
         "source": [
            "Here, we defined a function that proposes a new state based on its current configuration. This is called a _kernel_. The `hk.transform_with_state` decorator uses haiku to purify the function into something that is stateless."
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "id": "56d21ade",
         "metadata": {},
         "source": [
            "Finally, we draw samples from the Markov chain. We first take 100 burn-in steps, in the\n",
            "hope that the chain converges to the true distribution. After throwing away these first 100 samples, we collect a new set\n",
            "of 50 samples (25 in each chain) to estimate the posterior distribution.\n",
            "\n",
            "Note that `sample_markov_chain` (below) automatically takes care of distributing your\n",
            "computation across multiple devices. For simplicity, we assume you are running on a CPU and split the CPU up in two virtual devices. (See above, at the import section, where we've used\n",
            "`chex` set the number of devices to 2.)\n",
            "\n",
            "The following cell, that collects statistics from the Markov chain takes, about `10 minutes` to run on a CPU."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "f18731c6",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "WARNING:root:Number of trials is fixed at n_trials = [1437. 1438. 1439. ... 2871. 2872. 2873.]\n",
                  "/home/hylke/.local/lib/python3.11/site-packages/mubelnet/random.py:326: UserWarning: Explicitly requested dtype float64 requested in zeros_like is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
                  "  x_jk = jnp.zeros_like(b.transpose(), dtype=x.dtype)\n",
                  "/home/hylke/.local/lib/python3.11/site-packages/mubelnet/random.py:344: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
                  "  x_pad = jnp.zeros((n_pad, x.shape[1]), x.dtype)\n",
                  "/home/hylke/.local/lib/python3.11/site-packages/mubelnet/random.py:326: UserWarning: Explicitly requested dtype float64 requested in zeros_like is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
                  "  x_jk = jnp.zeros_like(b.transpose(), dtype=x.dtype)\n",
                  "/home/hylke/.local/lib/python3.11/site-packages/mubelnet/random.py:344: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
                  "  x_pad = jnp.zeros((n_pad, x.shape[1]), x.dtype)\n"
               ]
            }
         ],
         "source": [
            "n_chains = jax.device_count()\n",
            "\n",
            "params, states = sample_markov_chain(\n",
            "    next(key_seq),\n",
            "    kernel=kernel,\n",
            "    n_samples=50,\n",
            "    n_burnin_steps=100,\n",
            "    n_chains=n_chains,\n",
            ")\n",
            "\n",
            "_ = states['multinomial_belief/~/multinomial_layer']['phi'].block_until_ready()"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "id": "cc6c1598",
         "metadata": {},
         "source": [
            "After training the model, we can inspect what the model has learned. Note that, instead of a single point estimate of the parameters, we've obtained a distribution. To visualise the parameters, we take for simplicity the median. Let's take a look at $\\bm{\\Phi}^{(1)}$, the weights of the first layer."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "dad098e5",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<Figure size 640x480 with 0 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1250x600 with 10 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "<Figure size 640x480 with 0 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1250x600 with 10 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Aggregate posterior samples to visualise.\n",
            "phi_1st_layer = np.mean(states['multinomial_belief/~/multinomial_layer']['phi'], axis=[1])\n",
            "\n",
            "for i in range(n_chains):  # For each Markov chain.\n",
            "    plt.figure()\n",
            "    _, axes = plt.subplots(nrows=2, ncols=5, figsize=(12.5, 6))\n",
            "    plt.suptitle(f'Chain {i+1}')\n",
            "    # Plot the weights of all 10 hidden states.\n",
            "    for ax, phi in zip(axes.flatten(), phi_1st_layer[i]):\n",
            "        ax.set_axis_off()\n",
            "        image = phi.reshape(8, 8)\n",
            "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "4f16dad0",
         "metadata": {},
         "source": [
            "# Test perplexity.\n",
            "Given a distribution $p(x)$, perplexity is defined as $\\mathcal{L} = \\exp(S[p])$ with $S[p]$ the entropy of distribution $p(x)$. In practice, we evaluate the cross entropy with the emperical distribution so that\n",
            "$$\n",
            "\\ln \\mathcal{L} = -E_{\\mathrm{\\pmb{x}}}[ \\ln p(\\pmb{x}|\\pmb{X}_{\\mathrm{train}})] \\approx -\\frac{1}{m}\\sum_{i=1}^{m} \\ln p(\\pmb{x}^{(i)}|\\pmb{X}_{\\mathrm{train}})\n",
            "$$"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "388eefe4",
         "metadata": {},
         "source": [
            "To this end, we split the data in three sets: A training set $\\pmb{X}_{\\mathrm{train}}$, and two tests sets $\\pmb{X}_{\\mathrm{test}}^{A}$ and $\\pmb{X}_{\\mathrm{test}}^{B}$ containing 50% of the pixel intensities each (so that $\\pmb{X}_{\\mathrm{test}} = \\pmb{X}_{\\mathrm{test}}^A + \\pmb{X}_{\\mathrm{test}}^B$), similar to Ref. [1]. \n",
            "\n",
            "[1]: Wang, Chong, John Paisley, and David M. Blei. \"Online variational inference for the hierarchical Dirichlet process.\" Proceedings of the fourteenth international conference on artificial intelligence and statistics. JMLR Workshop and Conference Proceedings, 2011."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "a3e1b393",
         "metadata": {},
         "outputs": [],
         "source": [
            "X_test_A, X_test_B = holdout_split(next(key_seq), X_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a1705bc0",
         "metadata": {},
         "source": [
            "We then use $\\pmb{X}_{\\mathrm{train}}$ to infer the sample independent parameters $\\bm{\\phi}, \\bm{r}, c$ (i.e., without sample index $i$). With these, we use $\\pmb{X}_{\\mathrm{test}}^A $ to infer the sample _dependent_ parameters $\\pmb{\\theta}$ (i.e., with index $i$). Finally, we use $\\pmb{X}_{\\mathrm{test}}^{B}$ to estimate $p(\\pmb{x}|\\pmb{X}_{\\mathrm{train}})$."
         ]
      },
      {
         "cell_type": "markdown",
         "id": "40b69a8d",
         "metadata": {},
         "source": [
            "\n",
            "Specifically, we model the probabilities as categories $p(x_{ij}|\\pi_{ij}) = \\pi_{ij}^{x_{ij}}$ where $\\pi_{ij}$ is the probability to observe pixel intensity $j$ in sample $i$."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "616ab655",
         "metadata": {},
         "outputs": [],
         "source": [
            "def probability(params, state):\n",
            "    bottom_params = params.get(\"multinomial_belief/~/multinomial_layer\", {})\n",
            "    bottom_state = state[\"multinomial_belief/~/multinomial_layer\"]\n",
            "    phi = bottom_params.get(\"phi\", bottom_state.get(\"phi\"))\n",
            "    theta = bottom_state[\"copy[theta(1)]\"]\n",
            "    return theta @ phi"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "df4c9849",
         "metadata": {},
         "source": [
            "We estimate $\\pi_{ij}$ by averaging the posterior samples:\n",
            "$$\n",
            "\\pi_{ij}(\\pmb{X}_{\\mathrm{train}}, \\pmb{X}_{\\mathrm{test}}^A ) \n",
            "= \\int \\mathrm{d}\\pmb{\\phi} \\, \\mathrm{d}\\pmb{\\theta} \\, p(x_{ij}|\\pmb{\\phi}\\pmb{\\theta}) p(\\pmb{\\theta} | \\pmb{\\phi}, \\pmb{r}, c, \\pmb{X}_{\\mathrm{test}}^A ) p(\\pmb{\\phi}, \\pmb{r}, c|\\pmb{X}_{\\mathrm{train}}) \n",
            "\\approx \\frac{1}{S R} \\sum_{s=1}^S \\sum_{r=1}^{R} \\sum_{k=1}^K \\theta_{ik}^{(s, r)} \\phi_{kj}^{(s)}\n",
            "$$\n",
            "where $\\phi_{kj}^{(s)}$ with $s=1,\\dots,S$ denote posterior samples based on the training set $\\pmb{X}_{\\mathrm{train}}$ and $\\theta_{ik}^{(s, r)}$ the posterior samples $r=1,\\dots,R$ with respect to $\\pmb{X}_{\\mathrm{test}}^A $ given $\\phi_{kj}^{(s)}$ .\n",
            "\n",
            "Having inferred $\\pmb{\\phi}|\\pmb{X}_{\\mathrm{train}}$ above, let's infer $\\pmb{\\theta} | \\pmb{\\phi}, \\pmb{r}, c, \\pmb{X}_{\\mathrm{test}}^A$ for all the different realisations."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "cb19fe8e",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "WARNING:root:Number of trials is fixed at n_trials = Traced<ShapedArray(float32[360])>with<DynamicJaxprTrace(level=1/0)>\n"
               ]
            }
         ],
         "source": [
            "# Lift our the parameters r, c, and phi to keep them fixed.\n",
            "test_params, _ = freeze_trainable_states(states)\n",
            "\n",
            "# Configure Markov chain kernel for X_test_a with clamped parameters (training=False).\n",
            "init_test_fn = jax.jit(jax.vmap(partial(kernel.init, X=X_test_A, training=False)))\n",
            "kernel_test_fn = partial(kernel.apply, X=X_test_A, training=False)\n",
            "\n",
            "# Do inference on X_test_A for each posterior sample individually.\n",
            "probs = []\n",
            "for i in range(n_chains):\n",
            "    probs_i = []\n",
            "    for j in range(25):\n",
            "        params_s = jax.tree_util.tree_map(lambda x: x[i, j], test_params)\n",
            "        # Randomly initialise Markov chain.\n",
            "        keys_per_chain = random.split(next(key_seq), num=n_chains)\n",
            "        _, states_test_s_r = init_test_fn(keys_per_chain)\n",
            "        # Sample Markov chain.\n",
            "        _, states_test_s_r = sample_markov_chain(\n",
            "            next(key_seq),\n",
            "            n_samples=10,\n",
            "            kernel=kernel_test_fn,\n",
            "            params=params_s,\n",
            "            initial_state=states_test_s_r,\n",
            "            n_burnin_steps=20,\n",
            "        )\n",
            "        _ = states_test_s_r['multinomial_belief/~/cap_layer']['theta'].block_until_ready()\n",
            "        probs_ij = probability(params_s, states_test_s_r)\n",
            "        probs_i.append(probs_ij)\n",
            "    probs.append(jnp.stack(probs_i))\n",
            "\n",
            "probs = jnp.stack(probs)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "cace3019",
         "metadata": {},
         "source": [
            "Finally, the per intensity perplexity is computed on the separate hold-out set $\\pmb{X}_{\\mathrm{test}}^B$:\n",
            "$$\n",
            "\\mathcal{L}\\left(\\pmb{X}_{\\mathrm{test}}^B| \\pmb{\\pi}\\right) = \\exp \\left(-\\frac{1}{m} \\sum_{i=1}^m \\sum_{j=1}^n \\frac{x_{ij} \\ln {\\pi}_{ij}}{\\sum_{j=1}^n x_{ij}} \\right).\n",
            "$$"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "5615dd9c",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Training set perplexity: 33.99\n"
               ]
            }
         ],
         "source": [
            "probs_train = jnp.mean(probability(params, states), axis=(0, 1))\n",
            "print(f'Training set perplexity: {perplexity(X_train, probs_train):.2f}')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "cee51019",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Test set perplexity: 40.94\n"
               ]
            }
         ],
         "source": [
            "probs_test = probs.mean(axis=[0, 1, 2, 3])\n",
            "print(f'Test set perplexity: {perplexity(X_test_B, probs_test):.2f}')"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.6"
      },
      "vscode": {
         "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
