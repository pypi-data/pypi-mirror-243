{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynDiffix Usage Tutorial\n",
    "\n",
    "This notebook demonstrates how to use __SynDiffix__, an open-source library for generating statistically-accurate\n",
    "and strongly anonymous synthetic data from structured data.\n",
    "\n",
    "We'll go through the process of loading and inspecting a toy dataset, creating a synthetic dataset that mimics the original,\n",
    "computing some statistical properties over the two datasets and comparing them, and, finally, how to improve accuracy when\n",
    "analyzing synthetic data.\n",
    "\n",
    "### Setup\n",
    "\n",
    "The `syndiffix` package requires Python 3.10 or later. We can install it using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install syndiffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a toy dataset to play with, so let's install the `scikit-learn` package in order to use one of their popular reference datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to compute some statistical properties of the original and synthetic datasets in order to compare them, so let's install the `scipy` package as well: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our data\n",
    "\n",
    "For this tutorial, we are going to use the Diabetes dataset, which is a popular reference dataset containing some attributes of patients with diabetes and the progression of their illness one year after baseline.\n",
    "\n",
    "You can find more info about it [here](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset).\n",
    "You can see all the available toy datasets [here](https://scikit-learn.org/stable/datasets/toy_dataset.html).\n",
    "\n",
    "First, let's load our data and display some summary information about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     442 non-null    float64\n",
      " 1   sex     442 non-null    float64\n",
      " 2   bmi     442 non-null    float64\n",
      " 3   bp      442 non-null    float64\n",
      " 4   s1      442 non-null    float64\n",
      " 5   s2      442 non-null    float64\n",
      " 6   s3      442 non-null    float64\n",
      " 7   s4      442 non-null    float64\n",
      " 8   s5      442 non-null    float64\n",
      " 9   s6      442 non-null    float64\n",
      " 10  target  442 non-null    float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 38.1 KB\n",
      "None\n",
      "          age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
      "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
      "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
      "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
      "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
      "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
      "\n",
      "           s4        s5        s6  target  \n",
      "0   -0.002592  0.019907 -0.017646   151.0  \n",
      "1   -0.039493 -0.068332 -0.092204    75.0  \n",
      "2   -0.002592  0.002861 -0.025930   141.0  \n",
      "3    0.034309  0.022688 -0.009362   206.0  \n",
      "4   -0.002592 -0.031988 -0.046641   135.0  \n",
      "..        ...       ...       ...     ...  \n",
      "437 -0.002592  0.031193  0.007207   178.0  \n",
      "438  0.034309 -0.018114  0.044485   104.0  \n",
      "439 -0.011080 -0.046883  0.015491   132.0  \n",
      "440  0.026560  0.044529 -0.025930   220.0  \n",
      "441 -0.039493 -0.004222  0.003064    57.0  \n",
      "\n",
      "[442 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "data = sklearn.datasets.load_diabetes(as_frame=True)\n",
    "print(data.DESCR)\n",
    "print(data.frame.info())\n",
    "print(data.frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the attribute correlations in this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.19782187832853038, pvalue=2.806132121751573e-05)\n",
      "SignificanceResult(statistic=0.03740081502886254, pvalue=0.4328318674689041)\n",
      "SignificanceResult(statistic=0.5613820101065616, pvalue=4.567023927725032e-38)\n",
      "SignificanceResult(statistic=0.4162408981534322, pvalue=5.992783653793038e-20)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "print(scipy.stats.spearmanr(data.frame['target'], data.frame['age']))\n",
    "print(scipy.stats.spearmanr(data.frame['target'], data.frame['sex']))\n",
    "print(scipy.stats.spearmanr(data.frame['target'], data.frame['bmi']))\n",
    "print(scipy.stats.spearmanr(data.frame['target'], data.frame['bp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a moderate correlation between disease progression and body mass index / blood pressure and a low or no correlation with age and sex.\n",
    "\n",
    "### Creating a synthetic dataset\n",
    "\n",
    "Data with health information about individuals is usually privacy-sensitive and can't be shared freely with non-authorized analysts.\n",
    "Fortunately, using __SynDiffix__ we can create a synthetic dataset that preserves most of the statistical properties of the data while, at the same time, protecting subjects' privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     442 non-null    float64\n",
      " 1   sex     442 non-null    float64\n",
      " 2   bmi     442 non-null    float64\n",
      " 3   bp      442 non-null    float64\n",
      " 4   s1      442 non-null    float64\n",
      " 5   s2      442 non-null    float64\n",
      " 6   s3      442 non-null    float64\n",
      " 7   s4      442 non-null    float64\n",
      " 8   s5      442 non-null    float64\n",
      " 9   s6      442 non-null    float64\n",
      " 10  target  442 non-null    float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 38.1 KB\n",
      "None\n",
      "          age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0    0.009016 -0.044642 -0.024529 -0.026328 -0.011201 -0.018393  0.008142   \n",
      "1    0.009016 -0.044642 -0.023451 -0.046985  0.010876  0.028465  0.011824   \n",
      "2    0.009016 -0.044642 -0.069168 -0.037844 -0.047352 -0.015401  0.015229   \n",
      "3    0.012648 -0.044642 -0.069014 -0.026328 -0.060683 -0.049092  0.011824   \n",
      "4    0.009016 -0.044642 -0.069166 -0.043749 -0.037344 -0.042214  0.019187   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "437  0.023546  0.050680 -0.008362  0.070072  0.024574  0.031468 -0.043401   \n",
      "438  0.009016  0.050680 -0.013993  0.056301  0.020446 -0.019370 -0.047082   \n",
      "439  0.019913  0.050680  0.034474  0.011544  0.024574  0.041765 -0.021311   \n",
      "440  0.019913 -0.044642 -0.038540  0.021872  0.049113  0.001341 -0.017629   \n",
      "441  0.016281  0.050680  0.014272  0.063187  0.012191 -0.019086 -0.047082   \n",
      "\n",
      "           s4        s5        s6      target  \n",
      "0   -0.039493 -0.025953 -0.082131  128.000000  \n",
      "1   -0.039493 -0.049646 -0.086556  139.455612  \n",
      "2   -0.039493 -0.070934 -0.071494   48.862515  \n",
      "3   -0.039493 -0.057285 -0.085228   79.820580  \n",
      "4   -0.039493 -0.027129 -0.067351   72.000000  \n",
      "..        ...       ...       ...         ...  \n",
      "437  0.034309  0.013277  0.073480  172.443250  \n",
      "438  0.034309  0.012745  0.073480  172.638704  \n",
      "439  0.034309  0.044942  0.082623  233.344408  \n",
      "440  0.034309  0.007844  0.082724   94.552673  \n",
      "441  0.034309  0.026409  0.085919   90.548627  \n",
      "\n",
      "[442 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "from syndiffix import Synthesizer\n",
    "\n",
    "syn_data = Synthesizer(data.frame).sample()\n",
    "\n",
    "print(syn_data.info())\n",
    "print(syn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's measure the same correlations over the synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.10105320609583315, pvalue=0.03367470392579032)\n",
      "SignificanceResult(statistic=0.250068026895882, pvalue=9.964767433609745e-08)\n",
      "SignificanceResult(statistic=0.5524355817173319, pvalue=1.113492287222233e-36)\n",
      "SignificanceResult(statistic=0.17325645519948155, pvalue=0.00025230483799152704)\n"
     ]
    }
   ],
   "source": [
    "print(scipy.stats.spearmanr(syn_data['target'], syn_data['age']))\n",
    "print(scipy.stats.spearmanr(syn_data['target'], syn_data['sex']))\n",
    "print(scipy.stats.spearmanr(syn_data['target'], syn_data['bmi']))\n",
    "print(scipy.stats.spearmanr(syn_data['target'], syn_data['bp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between the `target` and the `bmi` attributes is preserved well, but the others are distorted.\n",
    "This happens because noise is produced during anonymization and synthesization.\n",
    "The greater the number of columns in the input and the fewer the rows, the noisier the output gets.\n",
    "\n",
    "### Improving accuracy\n",
    "\n",
    "We can make our analysis more accurate by not synthesizing unnecessary columns.\n",
    "When computing correlations, we only need 2 attributes at each step, so we can create a custom synthetic dataset for each computation separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.20049336982640237, pvalue=2.1724356135790848e-05)\n",
      "SignificanceResult(statistic=0.024652406428380392, pvalue=0.6048170855895556)\n",
      "SignificanceResult(statistic=0.518249695364917, pvalue=8.14201967530878e-32)\n",
      "SignificanceResult(statistic=0.47405933294930946, pvalue=3.8035222181486985e-26)\n"
     ]
    }
   ],
   "source": [
    "syn_data = Synthesizer(data.frame[['target', 'age']]).sample()\n",
    "print(scipy.stats.spearmanr(syn_data['target'], syn_data['age']))\n",
    "\n",
    "syn_data = Synthesizer(data.frame[['target', 'sex']]).sample()\n",
    "print(scipy.stats.spearmanr(syn_data['target'], syn_data['sex']))\n",
    "\n",
    "syn_data = Synthesizer(data.frame[['target', 'bmi']]).sample()\n",
    "print(scipy.stats.spearmanr(syn_data['target'], syn_data['bmi']))\n",
    "\n",
    "syn_data = Synthesizer(data.frame[['target', 'bp']]).sample()\n",
    "print(scipy.stats.spearmanr(syn_data['target'], syn_data['bp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the computed correlations are now close to the originals, making the utility of such an analysis high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
