{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Binary Classification: Training a K-Fold Model\n\n\ud83d\ude80 In this tutorial, we'll explore binary classification using K-fold cross validation. \nWe'll show you how to train a fusion model using K-Fold cross-validation with multimodal tabular data. \nSpecifically, we're using the :class:`~.TabularCrossmodalMultiheadAttention` model.\n\n\nKey Features:\n\n- \ud83d\udce5 Importing a model based on its path.\n- \ud83e\uddea Training and testing a model with k-fold cross validation.\n- \ud83d\udcc8 Plotting the loss curves of each fold.\n- \ud83d\udcca Visualising the results of a single K-Fold model using the :class:`~.ConfusionMatrix` class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport os\n\nfrom docs.examples import generate_sklearn_simulated_data\nfrom fusilli.data import get_data_module\nfrom fusilli.eval import ConfusionMatrix\nfrom fusilli.train import train_and_save_models\n\n# sphinx_gallery_thumbnail_number = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import the fusion model \ud83d\udd0d\nWe're importing only one model for this example, the :class:`~.TabularCrossmodalMultiheadAttention` model.\nInstead of using the :func:`~fusilli.utils.model_chooser.import_chosen_fusion_models` function, we're importing the model directly like with any other library method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fusilli.fusionmodels.tabularfusion.crossmodal_att import (\n    TabularCrossmodalMultiheadAttention,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Set the training parameters \ud83c\udfaf\nNow we're configuring our training parameters.\nFor using k-fold cross validation, the necessary parameters are:\n\n- ``kfold_flag``: the user sets this to True for k-fold cross validation.\n- ``num_k``: the number of folds to use. It can't be k=1.\n- ``log``: a boolean of whether to log the results using Weights and Biases (True) or not (False).\n- ``pred_type``: the type of prediction to be performed. This is either ``regression``, ``binary``, or ``classification``. For this example we're using binary classification.\n- ``loss_log_dir``: the directory to save the loss logs to. This is used for plotting the loss curves with ``log=False``.\n\nWe're also setting our own batch_size for this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = {\n    \"kfold_flag\": True,\n    \"num_k\": 5,  # number of folds\n    \"log\": False,\n    \"pred_type\": \"binary\",\n    \"batch_size\": 32,\n    \"loss_log_dir\": \"loss_logs/one_model_binary_kfold\",\n}\n\n# empty the loss log directory\nfor dir in os.listdir(params[\"loss_log_dir\"]):\n    for file in os.listdir(os.path.join(params[\"loss_log_dir\"], dir)):\n        os.remove(os.path.join(params[\"loss_log_dir\"], dir, file))\n    # remove dir\n    os.rmdir(os.path.join(params[\"loss_log_dir\"], dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generating simulated data \ud83d\udd2e\nTime to create some simulated data for our models to work their wonders on.\nThis function also simulated image data which we aren't using here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = generate_sklearn_simulated_data(\n    num_samples=500,\n    num_tab1_features=10,\n    num_tab2_features=10,\n    img_dims=(1, 100, 100),\n    params=params,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training the fusion model \ud83c\udfc1\nNow we're ready to train our model. We're using the :func:`~fusilli.train.train_and_save_models` function to train our model.\n\nFirst we need to create a data module using the :func:`~fusilli.data.get_data_module` function.\nThis function takes the following parameters:\n\n- ``fusion_model``: the fusion model to be trained.\n- ``params``: the parameters for training and testing.\n- ``batch_size``: the batch size for training and testing. This is optional and defaults to 8.\n\nThen we pass the data module, the parameters, and the fusion model to the :func:`~fusilli.train.train_and_save_models` function.\nWe're not using checkpointing for this example, so we set ``enable_checkpointing=False``. We're also setting ``show_loss_plot=True`` to plot the loss curves for each fold.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fusion_model = TabularCrossmodalMultiheadAttention\n\nprint(\"method_name:\", fusion_model.method_name)\nprint(\"modality_type:\", fusion_model.modality_type)\nprint(\"fusion_type:\", fusion_model.fusion_type)\n\ndm = get_data_module(\n    fusion_model=fusion_model, params=params, batch_size=params[\"batch_size\"]\n)\n\n# train and test\nsingle_model_list = train_and_save_models(\n    data_module=dm,\n    params=params,\n    fusion_model=fusion_model,\n    enable_checkpointing=False,  # False for the example notebooks\n    show_loss_plot=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the results \ud83d\udcca\nNow we're ready to plot the results of our model.\nWe're using the :class:`~.ConfusionMatrix` class to plot the confusion matrix.\nWe're seeing each fold's confusion matrices separately on the right, and the confusion matrix created from the concatenated validation sets from each fold on the left.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "confusion_matrix_fig = ConfusionMatrix.from_final_val_data(\n    single_model_list\n)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}