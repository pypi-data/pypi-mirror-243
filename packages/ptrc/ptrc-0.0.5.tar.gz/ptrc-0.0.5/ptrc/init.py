# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/31_init.ipynb.

# %% auto 0
__all__ = ['directions', 'directed_layers', 'init_s0', 'init_h0', 'init_c0', 'init_r0', 'init_rn']

# %% ../nbs/31_init.ipynb 6
#| export


# %% ../nbs/31_init.ipynb 8
#| export


# %% ../nbs/31_init.ipynb 11
#| export

# %% ../nbs/31_init.ipynb 13
#| export


# %% ../nbs/31_init.ipynb 15
try: import torch
except ImportError: torch = None

# %% ../nbs/31_init.ipynb 17
#| export


# %% ../nbs/31_init.ipynb 19
from atyp import IntQ, BoolQ, Tensor, TensorQ, DeviceQ
from chck import isnone, notnone

# %% ../nbs/31_init.ipynb 21
from .atyp import HiddenState, CellState, HiddenStates
from .enum import RecurrentLayer
from .util import last, batches

# %% ../nbs/31_init.ipynb 24
def directions(bidirectional: bool = False) -> int:    
    '''
    Calculate the number of directions in a recurrent neural network layer.

    Parameters
    ----------
    bidirectional : bool, optional
        Indicates whether the layer is bidirectional, defaults to False.

    Returns
    -------
    int
        The number of directions (1 for unidirectional, 2 for bidirectional).

    Examples
    --------
    >>> directions(True)
    2
    >>> directions(False)
    1
    '''
    return int(2 if bidirectional else 1)

# %% ../nbs/31_init.ipynb 25
def directed_layers(num_layers: int = 1, bidirectional: bool = False) -> int:
    '''
    Calculate the total number of layer-direction combinations in a recurrent neural network
    i.e. (D * L) where D is the number of directions and L is the number of layers.

    Parameters
    ----------
    num_layers : int, optional
        The number of layers in the RNN, defaults to 1.
        
    bidirectional : bool, optional
        Indicates whether the layers are bidirectional, defaults to False.

    Returns
    -------
    int
        The total number of layer-direction combinations.

    Examples
    --------
    >>> directed_layers(2, True)
    4
    '''
    return num_layers * directions(bidirectional)

# %% ../nbs/31_init.ipynb 26
def init_s0(
    s0: TensorQ = None, nlays: int = 1, hsize: int = 1, bsize: IntQ = None, 
    device: DeviceQ = None, bidirectional: BoolQ = None
) -> Tensor:
    '''Initalize state tensor for a layer if `s0` is None.
    
    Parameters
    ----------
    s0: Tensor, default: None
        The initial state tensor. If None, the state tensor is initialized to zeros.
        
    nlays: int, default: 1
        The number of layers (D * L), where D is the number of directions (1 or 2) and L is the number of layers

    hsize: int, default: 1
        The number of hidden units in each layer

    bsize: int, default: None
        The number of bsize in the input data. If None, the input data is assumed to be 
        unbatched (i.e. a single sequence).

    device: torch.device, default: None
        The device to use for the tensor. If None, the default device is used.

    bidirectional: bool, default: None
        Whether or not to double the number of layers. If True, the number of directions is 2, otherwise 1.
    '''
    nlays = directed_layers(nlays, bidirectional)
    if notnone(s0): pass
    elif isnone(bsize): s0 = torch.zeros(nlays, hsize)
    else: s0 = torch.zeros(nlays, bsize, hsize)
    return s0.to(device or s0.device)
    

# %% ../nbs/31_init.ipynb 27
def init_h0(
    h0: TensorQ = None, nlays: int = 1, hsize: int = 1, bsize: IntQ = None, 
    device: DeviceQ = None, bidirectional: BoolQ = None
) -> HiddenState: 
    '''Initalize hidden state tensor for a layer if `h0` is None.
    
    Parameters
    ----------
    h0: Tensor, default: None
        The initial hidden state tensor. If None, the hidden state tensor is initialized to zeros.
        
    nlays: int, default: 1
        The number of layers (D * L), where D is the number of directions (1 or 2) and L is the number of layers

    hsize: int, default: 1
        The number of hidden units in each layer

    bsize: int, default: None
        The number of bsize in the input data. If None, the input data is assumed to be 
        unbatched (i.e. a single sequence).

    device: torch.device, default: None
        The device to use for the tensor. If None, the default device is used.
    
    bidirectional: bool, default: None
        Whether or not to double the number of layers. If True, the number of directions is 2, otherwise 1.
    '''
    return init_s0(h0, nlays, hsize, bsize, device, bidirectional)

# %% ../nbs/31_init.ipynb 28
def init_c0(
    c0: TensorQ = None, nlays: int = 1, hcell: int = 1, bsize: IntQ = None, 
    device: DeviceQ = None, bidirectional: BoolQ = None
) -> CellState: 
    '''Initalize cell state tensor for a layer if `c0` is None.
    
    Parameters
    ----------
    c0: Tensor, default: None
        The initial cell state tensor. If None, the cell state tensor is initialized to zeros.
        
    nlays: int, default: 1
        The number of layers (D * L), where D is the number of directions (1 or 2) and L is the number of layers

    hcell: int, default: 1
        The number of cell units in each layer

    bsize: int, default: None
        The number of bsize in the input data. If None, the input data is assumed to be 
        unbatched (i.e. a single sequence).

    device: torch.device, default: None
        The device to use for the tensor. If None, the default device is used.

    bidirectional: bool, default: None
        Whether or not to double the number of layers. If True, the number of directions is 2, otherwise 1.
    '''
    return init_s0(c0, nlays, hcell, bsize, device, bidirectional)

# %% ../nbs/31_init.ipynb 29
def init_r0(
    x: Tensor, h0: TensorQ = None, c0: TensorQ = None, 
    nlays: int = 1, hcell: int = 1, hsize: IntQ = None, bsize: IntQ = None, 
    device: DeviceQ = None, batch_first: bool = True, bidirectional: BoolQ = None, 
    kind: RecurrentLayer = RecurrentLayer.LSTM
) -> HiddenStates:
    '''    
    Initialize the input tensor and the hidden / cell state tensors for a recurrent layer if they are `None`.

    Parameters
    ----------
    x : Tensor
        The input tensor to the recurrent layer.

    h0 : TensorQ, optional
        Initial hidden state, defaults to None.

    c0 : TensorQ, optional
        Initial cell state (for LSTM), defaults to None.

    nlays : int, optional
        Number of layers in the RNN, defaults to 1.

    hcell : int, optional
        Number of cells in each layer, defaults to 1.

    hsize : IntQ, optional
        Hidden size, defaults to None.

    bsize : IntQ, optional
        Batch size, defaults to None.

    device : DeviceQ, optional
        Device to use, defaults to None.

    batch_first : bool, optional
        If True, batch dimension comes first, defaults to True.

    bidirectional : BoolQ, optional
        If True, RNN is bidirectional, defaults to None.
        
    kind : RecurrentLayer, optional
        Type of recurrent layer (LSTM, GRU, etc.), defaults to LSTM.

    Returns
    -------
    HiddenStates
        A tuple of the input tensor and initialized hidden and cell states.

    Examples
    --------
    >>> init_r0(torch.rand(3, 5, 10))
    # Returns the input tensor with initialized hidden and cell states.
    '''
    nlays = directed_layers(nlays, bidirectional)
    
    bsize = bsize if notnone(bsize) else batches(x, batch_first)
    hsize = hsize if notnone(hsize) else hcell
    
    h0 = init_h0(h0, nlays, hsize, bsize, device, bidirectional=None)
    if kind == RecurrentLayer.LSTM:
        c0 = init_c0(c0, nlays, hcell, bsize, device, bidirectional=None)
        return x, (h0, c0)
    return x, h0

# %% ../nbs/31_init.ipynb 30
def init_rn(x: Tensor, retlast: bool = True) -> Tensor:
    '''Prepare the output tensor (i.e. rn) for a recurrent layer. If `retlast` is True, 
    the last output is returned, otherwise the output is returned.

    Parameters
    ----------
    x : Tensor
        The input tensor to the recurrent layer.
    retlast : bool, optional
        If True, returns the last output of the tensor, otherwise returns the entire tensor, defaults to True.

    Returns
    -------
    Tensor
        The initialized output tensor of the recurrent layer.

    Examples
    --------
    >>> init_rn(torch.rand(3, 5, 10))
    # Returns either the last output or the entire tensor, depending on `retlast`.
    '''
    return last(x) if retlast else x

# %% ../nbs/31_init.ipynb 32
#| export
