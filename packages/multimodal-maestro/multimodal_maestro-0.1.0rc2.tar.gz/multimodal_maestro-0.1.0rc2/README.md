
<div align="center">

  <h1>multimodal-maestro</h1>

  <br>

  [![version](https://badge.fury.io/py/multimodal-maestro.svg)](https://badge.fury.io/py/multimodal-maestro)
  [![license](https://img.shields.io/pypi/l/multimodal-maestro)](https://github.com/roboflow/multimodal-maestro/blob/main/LICENSE)
  [![python-version](https://img.shields.io/pypi/pyversions/multimodal-maestro)](https://badge.fury.io/py/multimodal-maestro)
  [![Gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/Roboflow/SoM)


</div>

## ðŸ‘‹ hello

Multimodal-Maestro gives you more control over large multimodal models to get the 
outputs you want. With more effective prompting tactics, you can get multimodal models 
to do tasks you didn't know (or think!) were possible.

ðŸš§ The project is still under construction and the API is prone to change.

## ðŸ’» install

```bash
pip install multimodal-maestro
```

## ðŸš€ examples

### GPT-4 Vision

```
Find dog.

>>> The dog is prominently featured in the center of the image with the label [9].
```

<details close>
<summary>ðŸ‘‰ read more</summary>

- **create marks**

```python

```

- **visualize marks**

```python

```

- **refine marks**

```python

```

- **extract related marks**

```python

```

</details>

![multimodal-maestro-2](https://github.com/roboflow/multimodal-maestro/assets/26109316/c04f2b18-2a1d-4535-9582-e5d3ec0a926e)

## ðŸ’œ acknowledgement

- [Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding
in GPT-4V](https://arxiv.org/abs/2310.11441) by Jianwei Yang, Hao Zhang, Feng Li, Xueyan
Zou, Chunyuan Li, Jianfeng Gao.

## ðŸ¦¸ contribution

We would love your help in making this repository even better! If you noticed any bug, 
or if you have any suggestions for improvement, feel free to open an 
[issue](https://github.com/roboflow/set-of-mark/issues) or submit a 
[pull request](https://github.com/roboflow/set-of-mark/pulls).
