Metadata-Version: 2.1
Name: pipseq
Version: 0.0.1
Summary: In Vitro Fertilization
Home-page: https://github.com/dsm-72/pipseq
Author: dsm-72
Author-email: sumner.magruder@yale.edu
License: Apache Software License 2.0
Keywords: in vitro fertilization pipseq
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3.11
Classifier: License :: OSI Approved :: Apache Software License
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: atyp
Requires-Dist: chck
Requires-Dist: nchr
Requires-Dist: nlit
Requires-Dist: psrc
Requires-Dist: xath
Requires-Dist: adic
Requires-Dist: pttn
Requires-Dist: putl
Provides-Extra: dev
Requires-Dist: numpy ; extra == 'dev'
Requires-Dist: pandas ; extra == 'dev'
Requires-Dist: scanpy ; extra == 'dev'
Requires-Dist: scprep ; extra == 'dev'
Requires-Dist: tqdm ; extra == 'dev'

# pipseq

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Developer Guide

### Setup

``` sh
# create conda environment
$ mamba env create -f env.yml

# update conda environment
$ mamba env update -n pipseq --file env.yml
```

### Install

``` sh
pip install -e .

# install from pypi
pip install pipseq
```

### nbdev

``` sh
# activate conda environment
$ conda activate pipseq

# make sure the pipseq package is installed in development mode
$ pip install -e .

# make changes under nbs/ directory
# ...

# compile to have changes apply to the pipseq package
$ nbdev_prepare
```

### Publishing

``` sh
# publish to pypi
$ nbdev_pypi

# publish to conda
$ nbdev_conda --build_args '-c conda-forge'
$ nbdev_conda --mambabuild --build_args '-c conda-forge -c dsm-72'
```

# Usage

## Installation

Install latest from the GitHub
[repository](https://github.com/dsm-72/pipseq):

``` sh
$ pip install git+https://github.com/dsm-72/pipseq.git
```

or from [conda](https://anaconda.org/dsm-72/pipseq)

``` sh
$ conda install -c dsm-72 pipseq
```

or from [pypi](https://pypi.org/project/pipseq/)

``` sh
$ pip install pipseq
```

## Documentation

Documentation can be found hosted on GitHub
[repository](https://github.com/dsm-72/pipseq)
[pages](https://dsm-72.github.io/pipseq/). Additionally you can find
package manager specific guidelines on
[conda](https://anaconda.org/dsm-72/pipseq) and
[pypi](https://pypi.org/project/pipseq/) respectively.

## PyTorch Documentation:

- [`TorchData`](https://pytorch.org/data/beta/index.html)
- [How to Package PyTorch
  Models](https://pytorch.org/docs/stable/package.html)
- [`torch.monitor.Event`](https://pytorch.org/docs/stable/monitor.html#torch.monitor.Event)
- [`torchvision`](https://pytorch.org/vision/stable/index.html)
- [`torchvision.Datasets.VisionDataset`](https://pytorch.org/vision/stable/generated/torchvision.datasets.VisionDataset.html#torchvision.datasets.VisionDataset)
- [`torchvision.utils.flow_to_image`](https://pytorch.org/vision/stable/generated/torchvision.utils.flow_to_image.html)

## PyTorch Models to Consider:

- [Diffusion Video
  AutoEncoders](https://github.com/man805/Diffusion-Video-Autoencoders)
- [ConvLSTM
  AutoEncoder](https://holmdk.github.io/2020/04/02/video_prediction.html)
- [Recurrent All Pairs Field Transforms for Optical
  Flow](https://github.com/princeton-vl/RAFT/blob/master/core/raft.py)
- [Optical Flow Toolbox
  (`mmflow`)](https://github.com/open-mmlab/mmflow/blob/master/docs/en/intro.md)
- [`torchvision.models.optical_flow.raft`](https://github.com/pytorch/vision/blob/main/torchvision/models/optical_flow/raft.py)
